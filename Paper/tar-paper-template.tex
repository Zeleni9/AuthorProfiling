% Paper template for TAR 2016
% (C) 2014 Jan Šnajder, Goran Glavaš, Domagoj Alagić, Mladen Karan
% TakeLab, FER

\documentclass[10pt, a4paper]{article}

\usepackage{tar2016}

\tolerance=1
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000

\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{scrextend}
\usepackage{setspace}
\usepackage{multirow}
\usepackage{enumitem}
\newcommand{\blank}[1]{\hspace*{#1}}
\usepackage[labelfont=bf]{caption}

\title{ Author Profiling}

\name{Filip Zelić, Borna Sirovica, Ivan-Dominik Ljubičić} 

\address{
University of Zagreb, Faculty of Electrical Engineering and Computing\\
Unska 3, 10000 Zagreb, Croatia\\ 
\texttt{\{filip.zelic,
borna.sirovica,
ivan-dominik.ljubicic\}@fer.hr}\\
}
          
         
\abstract{ 
\newgeometry{left=-5.2cm,right=-1cm}
In this paper, we present our approach to the author profiling task, a student project for Text Analysis and Retrieval course. Given a set of tweets by the same person, the task aims at identifying age, gender and personality traits of that person. We address age and gender prediction as a classification task and a personality prediction as a regression problem. We experimented with Support Vector Machine for classification and regression and other machine learning algorithms using a variety of custom designed features as well as features extracted from publicly available resources.\\
}

\begin{document}

\maketitleabstract

\section{Introduction}

Author profiling distinguishes between classes of authors by studying their sociolect aspect, i.e., how language is shared or how an author can be characterized from a psychological viewpoint. This information helps in identifying profiling aspects such as gender, age, native language, or personality type. 
\par
\vspace{1mm}
Author profiling is a problem of growing importance, among others for applications in forensics, security, and marketing. However, social profiling still remains a less-explored topic, even though the exponential growth of social networks increased its importance even further. While there were several publications that were trying to predict some demographical information such as gender, age, and native language \citep{argamon2003}, \citep{peersman2011}, as well as the personality type, and to perform author profiling in general \citep{argamon2009}, the real push forward was enabled by specialized competitions such as the PAN shared tasks on author profiling \citep{pardo2013}, \citep{rangel2014}, \citep{rangel2015}, which ran in 2013–2015. 
\par\vspace{1mm}
This paper presents our approach to the author profiling task. The task focused on predicting an author’s demographics (age and gender) and the big five personality traits \citep{mccrae2008} (agreeable, conscientious, extroverted, open, stable) from a set of tweets by the same target author.
\par\vspace{1mm}
This paper is organized as follows: Section 2
gives a detailed description of dataset used for
training and testing of our model. Section 3
presents general approach and methodology used
in the experiments, including a description of the
preprocessing, the features, and the learning
algorithms we used. Section 4 presents and
discusses our results and provides some deeper
analysis. Finally, Section 5 concludes and points
to possible directions for future work.

\section{Dataset}

The dataset we used consisted of English tweets from 152 users in XML format along with one \textit{truth.txt} file with age, gender and the Big Five personality traits labels for each user \citep{dataset2015}. For labeling age, the following classes were considered: 1) 18\textemdash 24, 2) 25\textemdash 34, 3) 35\textemdash 49, 4) 50+ and gender was labeled as male (M) or female (F). The distribution of the gender and age labels in the corpus is reported in Table~\ref{tab:narrow-table-1}. For the case of gender classes the corpus was balanced with 50\% of the tweets labeled as male and other half as female, but regarding age the      
distribution was skewed due to the lower number (around 22\%) of the older users (labels \textit{35\textemdash 49} and \textit{50+}) and higher number (around 78\%) of the younger users (labels \textit{18\textemdash 24} and \textit{25\textemdash 34}).
\begin{table}[h]
\caption{Distribution of Twitter users with respect to the age and gender labels in the corpus.}
\label{tab:narrow-table-1}
\vspace{-6mm}
\begin{center}
\begin{tabular}{llc}
\toprule
Trait & Label & Number of users\\
\midrule
\multirow{4}{*}{Age}
		&18\textemdash 24   & 58\\
    &25\textemdash 34   & 60\\
    &35\textemdash 49   & 22\\
    &50+   & 12\\
\midrule
\multirow{2}{*}{Gender}
		&Male   & 76\\
    &Female & 76\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

Regarding personality traits normalized numeric rating in [-0.5,0.5] range was given for each of the following properties:  extroverted, stable, agreeable, conscientious, and open. The mean for each trait is reported in Table~\ref{tab:narrow-table-2}.
\begin{table}[h]
\caption{Mean values of the Big Five personality traits in the corpus.}
\label{tab:narrow-table-2}
\vspace{-6mm}
\begin{center}
\begin{tabular}{lc}
\toprule
Personality trait & Mean value\\
\midrule
Extroverted  & 0.16\\
Stable   & 0.14\\
Agreeable  & 0.12\\
Conscientious     & 0.17\\
Open     & 0.24\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\section{Approach}

Along this section, we describe the steps we took to prepare features for the training of our supervised machine learning models. In subsection 3.1 we explain the preprocessing step in which we cleaned the data in order to get better performances for stylometric features. Subsection 3.2 explains extraction of various features for each separate subtask (age, gender and personality traits) and last subsection 3.3 describes classification and regression models we used tackling the task of author profiling.

\subsection{Preprocessing}

Preprocessing is done by creating a document for each user joining all his/hers tweets from the dataset. After the creation, the document is initially stripped of XML tags and cleared of all twitter specific characteristics such as hashtags, @replies as well as URLs from the text. While doing this step we save the count of mentions, hashtags and URLs for later use in feature modeling. When the preprocessing step is done, features need to be extracted. \\

\subsection{Feature extraction} 

As mentioned in the introduction, we used many different self-designed features and features extracted from publicly available resources for our machine learning algorithms.
\par\vspace{3mm}
\textbf{Lexicon Features}. We used several lexicons, both manually crafted and automatically generated:
\begin{itemize}[noitemsep,nolistsep]
\vspace{2mm}
\item \textbf{NRC Word-Emotion Association Lexicon} \citep{mohammad2013}: one dictionary for each of the eight primary human emotions: anger, anticipation, disgust, fear, joy, sadness, surprise, trust as well as dictionaries for positive and negative emotion word classification.
\vspace{1mm}
\item \textbf{Internet slang word lexicon} : personally made dictionary with most common words younger people like to use on the Internet.
\vspace{1mm}
\item \textbf{Frequent male and female words lexicon} \citep{schwartz2013}: dictionaries containing words most likely to be used by male or female person. Based on word usage frequency per million words.
\vspace{1mm}
\item \textbf{Frequent male and female function words lexicon} \citep{kiprov2015} : dictionaries containing function words, such as 'this','the','she', or 'not', most likely to be used by male or female person.
\end{itemize}
\vspace{2mm}
For each lexicon, we found the number of occurrences of lexicon terms in all tweets for each user, normalized by the total number of words in tweets. We instantiated separate features for the different lexicons.
\newpage
\textbf{Twitter-specific Features.} We used the following Twitter-specific features:
\begin{itemize}[noitemsep,nolistsep]
\vspace{1mm}
\item \textbf{Hashtags:} the number of hashtags;
\vspace{1mm}
\item \textbf{URLs:} the number of URLs posted;
\vspace{1mm}
\item \textbf{User mentions:} the number of mentions of users using the pattern @username;
\vspace{1mm}
\item \textbf{Emoticons:} the number of emoticons used in tweets.
\end{itemize}
\vspace{1mm}
All of the above counts are normalized by the total number of available tweets
for the target user; so they could be viewed as “average number per tweet”.
\par\vspace{3mm}
\textbf{Orthographic Features.} We used the following orthographic features:
\begin{itemize}[noitemsep,nolistsep] 
\vspace{1mm}
\item \textbf{Letter case:} the number of upper-case words and upper-case characters;
\vspace{1mm} 
\item \textbf{Character flooding:} the number of redundant character reduplication;
\vspace{1mm} 
\item \textbf{Word length:} average word length;
\vspace{1mm} 
\item \textbf{Tweet length:} average tweet length;
\vspace{1mm} 
\item \textbf{Specific characters:} usage of specific characters, such as the number of occurrences of the exclamation points, question marks or apostrophes.
\end{itemize}
\par\vspace{3mm}
\textbf{Term-level Features.} We used the following term-level features:
\begin{itemize}[noitemsep,nolistsep]
\vspace{1mm}
\item \textbf{n-grams:} TF-IDF matrices of unigrams and trigrams;
\vspace{1mm}
\item \textbf{F-score:} measure of contextuality and formality based on the frequency of the part of speech (POS) usage in a text (f.x below means the frequency of the part-of-speech x): 
\vspace{2mm}
\begin{spacing}{0.8}
\blank{0.2cm}$F =  0.5 * [(f.noun + f.adj + f.prep + \\
		\blank{0.9cm} f.art) – (f.pron + f.verb + f.adv +\\
		\blank{0.9cm} f.int) + 100] $
\end{spacing}
\item \textbf{POS tags:} frequency of certain POS tags such as nouns, verbs, prepositions, determiners, interjections, adverbs, adjectives etc.\\
\end{itemize}

\subsection{Supervised learning models}

Supervised machine learning models are used with hyperparameter optimization using grid search and k-fold cross validation on  70\% of training data. Regarding classification task for age and gender, we tested the following classification models: 
\begin{itemize}[noitemsep,nolistsep] 
	\vspace{2mm}
	\item Support Vector Machine Classification (SVC) with linear kernel and RBF kernel
	\vspace{1mm}
	\item Logistic Regression
	\vspace{1mm}
	\item Random Forest
\end{itemize}
\par\vspace{2mm}
On the other hand regarding regression task for personality traits, following regression models were tested:  
\begin{itemize}[noitemsep,nolistsep]
\vspace{2mm}
	\item Support Vector Machine Regression (SVR) with linear kernel and RBF kernel
	\vspace{1mm}
	\item Linear Regression
	\vspace{1mm}
\end{itemize}
\par\vspace{2mm}
Values of features were scaled using StandardScaler from sklearn python library in order to avoid complications that can arise in the classification stage when features with numeric values that differ a lot.

\vspace{2mm}
\section{Evaluation}
After extraction of features and normalization of feature values, we trained models from Section 3.3  on 70\% of data and evaluated them on other 30\% of data trough multiple iterations in which train and test data were shuffled. In this process we tried combinations of many features from Section 3.2 for each subtask. Best feature combinations are stated in the next few paragraphs. 
\par\vspace{1mm}
Regarding age subtask best scores were achieved using combinations of twitter-specific  and orthographic features along with TF-IDF scores of frequent trigrams. SVM model with RBF kernel proved to be the best choice model wise.
\par
In Gender classification subtask best results were obtained with the usage of male and female based lexicons together with orthographic features and F-score measure. SVM model with RBF kernel was proven to be the best choice for model selection also. The results of these two classification subtasks are given in the Table~\ref{tab:narrow-table-3}.
\begin{table}[h]
\caption{Age and Gender prediction accuracy}
\label{tab:narrow-table-3}
\vspace{-6mm}
\begin{center}
\begin{tabular}{lcc}
\toprule
Subtask & Classifier & Accuracy score\\
\midrule
 Gender & SVM (RBF kernel) & 77.2 \% \\
 Age & SVM (RBF kernel) & 76.1\%\\
\bottomrule
\end{tabular}
\end{center}
\end{table}
\par\vspace{-5mm}
Personality traits subtask was modeled as a regression problem. For every trait we chose the most appropriate feature combination which in general included word-emotion based lexicons as well as the F-score measure, POS tags frequencies and orthographic features such as upper-case word count, average tweet length and exclamation overload count. To measure accuracy of personality traits prediction root mean squared error (RMSE) measure was used. Lowest errors between predicted and actual scores were obtained using SVM Regression model. Results of this task are given in following Table~\ref{tab:narrow-table-4}.
\begin{table}[h]
\vspace{1mm}
\caption{Personality traits prediction accuracy}
\label{tab:narrow-table-4}
\vspace{-6mm}
\begin{center}
\begin{tabular}{lcc}
\midrule
Personality trait & Regression model & RMSE\\
\midrule
 Extroverted & SVR  (RBF kernel) & 0.142 \\
 Stable & SVR (RBF kernel)& 0.170 \\
 Agreeable & SVR  (RBF kernel)& 0.145 \\
 Conscientious & SVR  (RBF kernel)  & 0.153 \\
 Open & SVR  (RBF kernel) & 0.156 \\
\bottomrule
\end{tabular}
\end{center}
\end{table}
\par

\section{Conclusion and future work}

This paper proposes a supervised machine learning technique for solving the author profiling problem of determining author's age, gender and Big Five personality traits trough feature extraction from tweet corpus. 
\par\vspace{1mm}
Tackling this challenging task we combined a large number of various features in order to train and evaluate our machine learning models. The main problem was that we could not evaluate our models on the most real case scenario because we did not find a publicly available evaluation dataset so the models were evaluated on 30\% of the training dataset.
\par\vspace{1mm}
Even though evaluation showed good results for age gender and personality trait prediction  \citep{rangel2015}, we feel that there is a lot more to gain. For example, in the future work we could develop a more sophisticated approach for personality trait identification, considering more specific features and preprocessing for each personality trait separately. We could also experiment with descriptive LSA (Latent Semantic Analysis) and discriminative SOA (Second Order Attributes) features analyzed in paper \citep{escalante2015}.

\bibliographystyle{tar2016}
\bibliography{tar2016} 

\end{document}